import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import initialize_agent, Tool
from langchain_experimental.tools import PythonREPLTool  # int√©rprete de Python de Camel AI
from typing import TypedDict, List, Any, Optional, Optional
from langchain.prompts import PromptTemplate
from langchain_ollama import ChatOllama
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Any
import sys

import psycopg
from psycopg import sql
from langgraph.checkpoint.postgres import PostgresSaver
import uuid

# Suprimir warnings de Google Cloud
import warnings
warnings.filterwarnings('ignore', message='.*ALTS.*')
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GRPC_TRACE'] = ''

# ======================
# 0. Configuraci√≥n y creaci√≥n de BD PostgreSQL
# ======================

def load_db_config():
    """Carga la configuraci√≥n de la base de datos desde variables de entorno"""
    load_dotenv()
    
    db_config = {
        'host': os.getenv('POSTGRES_HOST', 'localhost'),
        'port': os.getenv('POSTGRES_PORT', '5432'),
        'user': os.getenv('POSTGRES_USER', 'postgres'),
        'password': os.getenv('POSTGRES_PASSWORD'),
        'database': os.getenv('POSTGRES_DB', 'langgraph_analysis')
    }
    
    # Verificar que las credenciales est√©n configuradas
    if not db_config['password']:
        print("‚ùå Error: POSTGRES_PASSWORD no est√° configurada en el archivo .env")
        sys.exit(1)
    
    return db_config

def database_exists(cursor, db_name):
    """Verifica si una base de datos existe"""
    cursor.execute(
        "SELECT 1 FROM pg_database WHERE datname = %s", 
        (db_name,)
    )
    return cursor.fetchone() is not None

def create_database_if_not_exists():
    """
    Crea la base de datos si no existe.
    Retorna True si la BD se cre√≥ o ya exist√≠a, False en caso de error.
    """
    db_config = load_db_config()
    target_db = db_config['database']
    
    print(f"üîç Verificando existencia de base de datos: {target_db}")
    
    # Conectar a PostgreSQL usando la BD por defecto 'postgres'
    try:
        with psycopg.connect(
            host=db_config['host'],
            port=db_config['port'],
            user=db_config['user'],
            password=db_config['password'],
            dbname='postgres',  # Conectar a la BD por defecto
            autocommit=True
        ) as conn:
            with conn.cursor() as cursor:
                # Verificar si la base de datos existe
                if database_exists(cursor, target_db):
                    print(f"‚úÖ Base de datos '{target_db}' ya existe")
                    return True
                else:
                    print(f"üìù Base de datos '{target_db}' no existe. Creando...")
                    
                    # Crear la base de datos
                    cursor.execute(sql.SQL("CREATE DATABASE {}").format(
                        sql.Identifier(target_db)
                    ))
                    
                    print(f"‚úÖ Base de datos '{target_db}' creada exitosamente")
                    return True
            
    except psycopg.Error as e:
        print(f"‚ùå Error al gestionar la base de datos PostgreSQL:")
        print(f"   C√≥digo de error: {e.pgcode}")
        print(f"   Mensaje: {e.pgerror}")
        
        # Errores comunes y sugerencias
        if "authentication failed" in str(e).lower():
            print("   üí° Sugerencia: Verifica las credenciales en el archivo .env")
        elif "connection refused" in str(e).lower():
            print("   üí° Sugerencia: Verifica que PostgreSQL est√© ejecut√°ndose")
        elif "permission denied" in str(e).lower():
            print("   üí° Sugerencia: El usuario necesita permisos CREATEDB")
        
        return False
    except Exception as e:
        print(f"‚ùå Error inesperado: {e}")
        return False

def test_target_database_connection():
    """Prueba la conexi√≥n a la base de datos objetivo"""
    db_config = load_db_config()
    
    try:
        with psycopg.connect(
            host=db_config['host'],
            port=db_config['port'],
            user=db_config['user'],
            password=db_config['password'],
            dbname=db_config['database']
        ) as conn:
            pass  # Conexi√≥n exitosa
        print(f"‚úÖ Conexi√≥n exitosa a la base de datos '{db_config['database']}'")
        return True
    except psycopg.Error as e:
        print(f"‚ùå Error al conectar a la base de datos objetivo: {e}")
        return False

# ======================
# 1. Configuraci√≥n inicial
# ======================
load_dotenv() # Cargar variables de entorno (.env debe contener GOOGLE_API_KEY)

# Crear BD antes de continuar
print("üöÄ Inicializando sistema de an√°lisis de datos...")
if not create_database_if_not_exists():
    print("‚ùå No se pudo crear o acceder a la base de datos. Terminando aplicaci√≥n.")
    sys.exit(1)

# Probar conexi√≥n a la BD objetivo
if not test_target_database_connection():
    print("‚ùå No se pudo conectar a la base de datos objetivo. Terminando aplicaci√≥n.")
    sys.exit(1)

api_key = os.getenv("GOOGLE_API_KEY")
os.makedirs("./outputs", exist_ok=True) # Crear carpeta para guardar gr√°ficos si no existe

# Cargar dataset con pandas
df = pd.read_excel("./Data/ncr_ride_bookings.xlsx")

# Inicializar LLM
llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=api_key, temperature=0)
# llm = ChatOllama(model="gemma3", temperature=0)

# ======================
# 1,5. Configurar PostgresSaver para guardar checkpoints
# ======================

def get_postgres_connection_string():
    """Genera la cadena de conexi√≥n para PostgreSQL usando psycopg3"""
    db_config = load_db_config()
    return f"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"

# Configurar PostgresSaver correctamente
connection_string = get_postgres_connection_string()

try:
    # M√©todo 1: Crear conexi√≥n directa usando psycopg
    import psycopg
    conn = psycopg.connect(connection_string)
    
    # Crear PostgresSaver con la conexi√≥n directa
    checkpoint_saver = PostgresSaver(conn)
    checkpoint_saver.setup()
    
    print("‚úÖ PostgresSaver configurado exitosamente")
    
except Exception as e:
    print(f"‚ùå Error configurando PostgresSaver: {e}")
    print("‚ö†Ô∏è Continuando sin checkpoints...")
    checkpoint_saver = None

# ======================
# 2. Definir int√©rprete Python con acceso a df
# ======================
python_repl = PythonREPLTool()

def run_python_with_df(code: str, error_context: Optional[str] = None):
    """
    Ejecuta c√≥digo Python con acceso al DataFrame `df` ya cargado.
    Incluye contexto de errores previos para mejor debugging.
    """
    local_vars = {"df": df, "pd": pd, "plt": plt, "sns": sns, "os": os}

    prohibited_patterns = [
        "pd.DataFrame",
        "df = ",
        "data = {",
        "= pd.DataFrame",
        "DataFrame(",
        "# Datos de ejemplo",
        "datos de ejemplo",
        "reemplaza con tu DataFrame"
    ]
    
    code_lower = code.lower()
    for pattern in prohibited_patterns:
        if pattern.lower() in code_lower:
            return {
                "success": False,
                "result": None,
                "error": f"C√≥digo bloqueado. Detectado intento de crear DataFrame: '{pattern}'. Usa SOLO el df existente.",
                "error_type": "prohibited_pattern"
            }

    try:
        import ast
        parsed = ast.parse(code)
        if parsed.body and isinstance(parsed.body[-1], ast.Expr):
            last_expr = parsed.body.pop()
            exec(compile(ast.Module(parsed.body, type_ignores=[]), filename="<ast>", mode="exec"), {}, local_vars)
            result = eval(compile(ast.Expression(last_expr.value), filename="<ast>", mode="eval"), {}, local_vars)
        else:
            exec(code, {}, local_vars)
            result = None

        return {
            "success": True,
            "result": result if result is not None else "‚úÖ C√≥digo ejecutado con √©xito.",
            "error": None,
            "error_type": None
        }
    except Exception as e:
        error_type = type(e).__name__
        return {
            "success": False,
            "result": None,
            "error": str(e),
            "error_type": error_type
        }
    
def get_tools_summary(tools: List[Tool]) -> str:
    """Devuelve un resumen con nombre y descripci√≥n de cada tool."""
    return "\n".join([f"- {t.name}: {t.description}" for t in tools])


# ======================
# 3. Tools
# ======================
def get_dataframe(_):
    """
    Devuelve el DataFrame completo al LLM.
    Este tool permite que el agente acceda a 'df' directamente para cualquier an√°lisis.
    """
    return df

def get_summary(_):
    """Devuelve un resumen general del dataset"""
    return str(df.describe(include="all"))

def get_columns(_):
    """Devuelve las columnas del dataset"""
    return str(df.columns.tolist())

def get_missing_values(_):
    """Devuelve la cantidad de valores nulos por columna"""
    return str(df.isnull().sum())

def get_dtypes_and_uniques(_):
    """Devuelve los tipos de datos de cada columna y la cantidad de valores √∫nicos."""
    return str(pd.DataFrame({
        "dtype": df.dtypes,
        "unique_values": df.nunique()
}))

def get_categorical_distribution(column: str):
    """Devuelve la distribuci√≥n de frecuencias de una columna categ√≥rica."""
    if column not in df.columns:
        return f"Columna {column} no encontrada."
    return str(df[column].value_counts(dropna=False).head(20))

def get_numeric_dispersion(_):
    """Devuelve rango, varianza y desviaci√≥n est√°ndar de variables num√©ricas."""
    numeric_cols = df.select_dtypes(include=["number"])
    return str(numeric_cols.agg(["min", "max", "var", "std"]))

def get_correlations(_):
    """Devuelve la matriz de correlaciones entre variables num√©ricas."""
    numeric_cols = df.select_dtypes(include=["number"])
    return str(numeric_cols.corr())

def detect_outliers(column: str):
    """Devuelve los valores at√≠picos (seg√∫n IQR) de una columna num√©rica."""
    if column not in df.columns:
        return f"Columna {column} no encontrada."
    if not pd.api.types.is_numeric_dtype(df[column]):
        return f"La columna {column} no es num√©rica."
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    outliers = df[(df[column] < Q1 - 1.5 * IQR) | (df[column] > Q3 + 1.5 * IQR)][column]
    return str(outliers.head(50))  # solo mostramos algunos

def get_time_series_summary(_):
    """Devuelve la cantidad de viajes por fecha (si existe columna de fecha)."""
    if "Date" not in df.columns:
        return "No existe columna Date."
    df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
    return str(df.groupby(df["Date"].dt.date).size().head(30))

# Gr√°ficas

def plot_histogram(column: str):
    """Genera un histograma de una columna num√©rica, lo guarda en carpeta y lo muestra en ventana."""
    if column not in df.columns:
        return f"Columna {column} no encontrada."
    if not pd.api.types.is_numeric_dtype(df[column]):
        return f"La columna {column} no es num√©rica."
    
    plt.figure(figsize=(10,6))
    df[column].dropna().hist(bins=30, edgecolor="black", alpha=0.7)
    plt.title(f"Histograma de {column}", fontsize=16)
    plt.xlabel(column, fontsize=12)
    plt.ylabel("Frecuencia", fontsize=12)
    plt.grid(axis="y", alpha=0.5)

    file_path = f"./outputs/histogram_{column}.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.show()
    return f"‚úÖ Histograma generado y guardado en {file_path}"

def plot_correlation_heatmap(_):
    """Genera un heatmap de correlaciones entre variables num√©ricas."""
    numeric_cols = df.select_dtypes(include=["number"])
    if numeric_cols.empty:
        return "No hay columnas num√©ricas para correlacionar."

    import seaborn as sns
    plt.figure(figsize=(12,8))
    sns.heatmap(numeric_cols.corr(), annot=True, cmap="coolwarm", fmt=".2f")
    plt.title("Mapa de calor de correlaciones", fontsize=16)

    file_path = "./outputs/correlation_heatmap.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.show()
    return f"‚úÖ Heatmap de correlaciones generado y guardado en {file_path}"

def plot_time_series(_):
    """Genera una serie temporal de la cantidad de viajes por d√≠a (si existe columna Date)."""
    if "Date" not in df.columns:
        return "No existe columna Date."
    df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
    ts = df.groupby(df["Date"].dt.date).size()

    plt.figure(figsize=(14,6))
    ts.plot(kind="line", marker="o", alpha=0.7)
    plt.title("Cantidad de viajes por d√≠a", fontsize=16)
    plt.xlabel("Fecha", fontsize=12)
    plt.ylabel("Cantidad de viajes", fontsize=12)
    plt.grid(True, alpha=0.5)

    file_path = "./outputs/time_series.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.show()
    return f"‚úÖ Serie temporal generada y guardada en {file_path}"

def plot_payment_method_distribution(_):
    """Genera un gr√°fico de barras de los m√©todos de pago ordenados por frecuencia."""
    if "Payment Method" not in df.columns:
        return "No existe columna Payment Method."
    
    counts = df["Payment Method"].value_counts().sort_values(ascending=False)
    
    plt.figure(figsize=(10,6))
    counts.plot(kind="bar", color="skyblue", edgecolor="black")
    plt.title("M√©todos de Pago m√°s frecuentes", fontsize=16)
    plt.xlabel("M√©todo de Pago", fontsize=12)
    plt.ylabel("Frecuencia", fontsize=12)
    plt.xticks(rotation=45, ha="right")
    plt.grid(axis="y", alpha=0.5)

    file_path = "./outputs/payment_method_distribution.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.show()
    return f"‚úÖ Gr√°fico de m√©todos de pago generado y guardado en {file_path}"

def plot_booking_value_by_vehicle_type(_):
    """Genera un boxplot de Booking Value seg√∫n Vehicle Type."""
    if "Booking Value" not in df.columns or "Vehicle Type" not in df.columns:
        return "No existen las columnas necesarias (Booking Value, Vehicle Type)."
    
    plt.figure(figsize=(12,6))
    import seaborn as sns
    sns.boxplot(data=df, x="Vehicle Type", y="Booking Value", palette="Set2")
    plt.title("Distribuci√≥n de Booking Value por tipo de veh√≠culo", fontsize=16)
    plt.xlabel("Tipo de Veh√≠culo", fontsize=12)
    plt.ylabel("Booking Value", fontsize=12)
    plt.xticks(rotation=30, ha="right")
    plt.grid(axis="y", alpha=0.5)

    file_path = "./outputs/booking_value_by_vehicle_type.png"
    plt.savefig(file_path, dpi=300, bbox_inches="tight")
    plt.show()
    return f"‚úÖ Boxplot generado y guardado en {file_path}"

tools = [
    Tool(name="get_summary", func=get_summary, description="Muestra un resumen estad√≠stico del dataset"),
    Tool(name="get_columns", func=get_columns, description="Muestra las columnas del dataset"),
    Tool(name="get_missing_values", func=get_missing_values, description="Muestra los valores nulos en el dataset"),
    Tool(name="get_dtypes_and_uniques", func=get_dtypes_and_uniques, description="Muestra tipos de datos y cantidad de valores √∫nicos por columna"),
    Tool(name="get_categorical_distribution", func=get_categorical_distribution, description="Muestra distribuci√≥n de valores en una columna categ√≥rica"),
    Tool(name="get_numeric_dispersion", func=get_numeric_dispersion, description="Muestra rango, varianza y desviaci√≥n est√°ndar de columnas num√©ricas"),
    Tool(name="get_correlations", func=get_correlations, description="Muestra correlaciones entre variables num√©ricas"),
    Tool(name="detect_outliers", func=detect_outliers, description="Detecta valores at√≠picos en una columna num√©rica"),
    Tool(name="get_time_series_summary", func=get_time_series_summary, description="Muestra cantidad de viajes por fecha"),
    Tool(name="plot_histogram", func=plot_histogram, description="Genera un histograma de una columna num√©rica"),
    Tool(name="plot_correlation_heatmap", func=plot_correlation_heatmap, description="Genera un heatmap de correlaciones entre variables num√©ricas"),
    Tool(name="plot_time_series", func=plot_time_series, description="Genera una serie temporal de cantidad de viajes por d√≠a"),
    Tool(name="plot_payment_method_distribution", func=plot_payment_method_distribution, description="Genera un gr√°fico de barras de m√©todos de pago ordenados por frecuencia"),
    Tool(name="plot_booking_value_by_vehicle_type", func=plot_booking_value_by_vehicle_type, description="Genera un boxplot de Booking Value por tipo de veh√≠culo"),
    Tool(
        name="Python_Interpreter",
        func=run_python_with_df,
        description="Ejecuta c√≥digo Python con acceso al DataFrame `df` cargado desde Excel. Usa este df para limpiar datos, convertir columnas y generar gr√°ficos."
    ),
]

# ======================
# Prompt unificado para Python
# ======================
def build_code_prompt(query: str, execution_history: List[dict] = None, df_info: dict = None):
    """
    Genera un prompt contextual que incluye historial de errores y informaci√≥n del DataFrame.
    """
    
    # Informaci√≥n b√°sica del DataFrame
    if df_info is None:
        df_info = {
            "columns": list(df.columns),
            "dtypes": df.dtypes.to_dict(),
            "shape": df.shape,
            "sample": df.head(2).to_dict()
        }
    
    base_prompt = f"""
Eres un experto en an√°lisis de datos con Python y pandas.

INFORMACI√ìN DEL DATAFRAME:
- Columnas disponibles: {df_info['columns']}
- Tipos de datos: {', '.join([f"{col}: {dtype}" for col, dtype in df_info['dtypes'].items()])}
- Dimensiones: {df_info['shape']}

REGLAS IMPORTANTES:
1. Usa EXCLUSIVAMENTE el DataFrame 'df' que ya est√° cargado
2. NO crees ni simules nuevos DataFrames ni datos de ejemplo
3. Para gr√°ficos, guarda en './outputs/' y usa plt.show()
4. Si trabajas con columnas de tiempo, verifica su tipo primero

TAREA: {query}
"""

    # Agregar historial de errores si existe
    if execution_history:
        base_prompt += "\n\nHISTORIAL DE INTENTOS PREVIOS:\n"
        for i, attempt in enumerate(execution_history, 1):
            if not attempt['success']:
                base_prompt += f"""
Intento {i}:
C√≥digo: {attempt.get('code', 'N/A')}
Error: {attempt['error']} (Tipo: {attempt['error_type']})
"""
        
    base_prompt += "\n‚ö†Ô∏è IMPORTANTE: Analiza los errores anteriores y genera un c√≥digo DIFERENTE que los evite. Solo genera un gr√°fico UNICAMENTE si el usuario lo pide.\n"
    base_prompt += "\nResponde SOLO con c√≥digo Python ejecutable, sin explicaciones ni markdown:"
    
    return base_prompt

# Mapeo para invocarlos f√°cilmente
tool_dict = {t.name: t for t in tools}

# ======================
# 4. Definir estado del grafo
# ======================
class AgentState(TypedDict):
    query: str
    action: str
    result: Any
    thought: str
    history: List[str]
    execution_history: List[dict]  # Nuevo: historial detallado de ejecuciones
    iteration_count: int           # Nuevo: contador de iteraciones
    max_iterations: int           # Nuevo: l√≠mite de iteraciones
    df_info: dict                 # Nuevo: informaci√≥n cached del DataFrame
    success: bool                 # Nuevo: flag de √©xito
    final_error: Optional[str]    # Nuevo: error final si no se pudo resolver
    thread_id: str  # NUEVO: ID √∫nico para identificar la conversaci√≥n

# ======================
# 5. Nodos del grafo
# ======================
def node_clasificar(state: AgentState):
    """El LLM decide qu√© acci√≥n tomar con contexto mejorado"""
    
    # Obtener informaci√≥n del DataFrame si no existe
    if not state.get("df_info"):
        state["df_info"] = {
            "columns": list(df.columns),
            "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
            "shape": df.shape,
            "sample": df.head(2).to_dict()
        }
    
    # Contexto de iteraciones previas
    iteration_context = ""
    if state["iteration_count"] > 0:
        iteration_context = f"\nEsta es la iteraci√≥n #{state['iteration_count'] + 1}. Intentos previos han fallado."
        if state["execution_history"]:
            last_error = state["execution_history"][-1].get("error", "")
            iteration_context += f"\n√öltimo error: {last_error}"

    tools_summary = get_tools_summary(tools)

    prompt = f"""
Eres un asistente de an√°lisis de datos experto. Analiza esta consulta y decide la mejor acci√≥n.

CONSULTA: {state['query']}
DATAFRAME INFO: Columnas = {state['df_info']['columns']}, Shape = {state['df_info']['shape']}
{iteration_context}

HERRAMIENTAS DISPONIBLES:
{tools_summary}

DECISI√ìN:
Analiza la consulta y selecciona la herramienta m√°s adecuada. 
Si ninguna herramienta especializada es suficiente, usa Python_Interpreter.

Formato de salida:
Thought: <an√°lisis detallado de la consulta y estrategia>
Action: <nombre exacto de la herramienta elegida>
"""

    response = llm.invoke(prompt).content.strip()

    # Extraer thought y action
    thought, action = "", "Python_Interpreter"
    for line in response.splitlines():
        if line.lower().startswith("thought:"):
            thought = line.split(":", 1)[1].strip()
        elif line.lower().startswith("action:"):
            action = line.split(":", 1)[1].strip()

    state["thought"] = thought
    state["action"] = action
    state["history"].append(f"Iteraci√≥n {state['iteration_count']} - Clasificar ‚Üí {thought[:100]}...")

    print(f"\nüß† Iteraci√≥n {state['iteration_count']} - Thought: {thought}")
    print(f"‚û°Ô∏è Action: {action}")

    return state

def node_ejecutar_python(state: AgentState):
    """Ejecuta c√≥digo Python con manejo robusto de errores y contexto"""
    
    print(f"‚öôÔ∏è Ejecutando Python - Intento {state['iteration_count'] + 1}")
    
    # Generar c√≥digo con contexto completo
    code_prompt = build_code_prompt(
        state["query"], 
        state["execution_history"], 
        state["df_info"]
    )
    
    # Generar c√≥digo
    python_code = llm.invoke(code_prompt).content.strip()
    
    # Limpiar markdown
    if python_code.startswith("```"):
        python_code = python_code.strip("`")
        if python_code.lower().startswith("python"):
            python_code = python_code[len("python"):].strip()
        python_code = python_code.replace("```", "").strip()

    print(f"\nüîç C√≥digo generado:\n{python_code}")
    
    # Ejecutar c√≥digo
    execution_result = run_python_with_df(python_code)
    
    # Crear registro de ejecuci√≥n
    execution_record = {
        "iteration": state["iteration_count"],
        "code": python_code,
        "success": execution_result["success"],
        "result": execution_result["result"],
        "error": execution_result["error"],
        "error_type": execution_result["error_type"]
    }
    
    # Actualizar historial
    state["execution_history"].append(execution_record)
    state["result"] = execution_result["result"]
    state["success"] = execution_result["success"]
    
    if execution_result["success"]:
        print(f"‚úÖ √âxito: {execution_result['result']}")
    else:
        print(f"‚ùå Error: {execution_result['error']}")
        state["final_error"] = execution_result["error"]
    
    state["history"].append(f"Ejecutar Python ‚Üí {'√âxito' if execution_result['success'] else 'Error: ' + str(execution_result['error'])}")
    
    return state

def node_validar_y_decidir(state: AgentState):
    """Valida el resultado y decide si continuar iterando"""
    
    state["iteration_count"] += 1
    success = state.get("success", False)
    max_iterations = state.get("max_iterations", 3)
    
    print(f"\nüîç Validaci√≥n - Iteraci√≥n {state['iteration_count']}")
    print(f"   √âxito: {success}")
    print(f"   Iteraciones restantes: {max_iterations - state['iteration_count']}")
    
    # Decidir pr√≥xima acci√≥n
    if success:
        state["next_node"] = "responder"
        print("   ‚û°Ô∏è Decisi√≥n: Proceder a responder (√©xito)")
    elif state["iteration_count"] >= max_iterations:
        state["next_node"] = "responder"
        print("   ‚û°Ô∏è Decisi√≥n: Proceder a responder (m√°ximo de iteraciones alcanzado)")
    else:
        state["next_node"] = "clasificar"
        print("   ‚û°Ô∏è Decisi√≥n: Nueva iteraci√≥n")
    
    state["history"].append(f"Validar ‚Üí Iteraci√≥n {state['iteration_count']}, √âxito: {success}, Pr√≥ximo: {state['next_node']}")
    
    return state

def node_responder(state: AgentState):
    """Genera la respuesta final basada en todo el contexto y guarda el checkpoint"""
    
    success = state.get("success", False)
    
    if success:
        prompt = f"""
Pregunta del usuario: {state['query']}
Resultado obtenido: {state['result']}
N√∫mero de iteraciones necesarias: {state['iteration_count']}

Genera una respuesta clara y amigable en espa√±ol explicando qu√© se logr√≥.
"""
    else:
        errors_summary = []
        for record in state["execution_history"]:
            if not record["success"]:
                errors_summary.append(f"- {record['error_type']}: {record['error']}")
        
        prompt = f"""
Pregunta del usuario: {state['query']}
Despu√©s de {state['iteration_count']} iteraciones, no se pudo completar la tarea.

Errores encontrados:
{chr(10).join(errors_summary)}

Genera una respuesta emp√°tica en espa√±ol explicando:
1. Que se intent√≥ resolver la consulta m√∫ltiples veces
2. Los principales problemas encontrados (en t√©rminos simples)
3. Sugerencias para el usuario (ej: verificar formato de datos, columnas, etc.)
"""

    respuesta = llm.invoke(prompt).content
    print(f"\nü§ñ Respuesta Final:\n{respuesta}")
    
    # Log final
    state["history"].append(f"Responder ‚Üí Finalizado con {'√©xito' if success else 'error'}")
    
    return state

def route_after_validation(state: AgentState):
    """Determina la siguiente ruta basada en la validaci√≥n"""
    success = state.get("success", False)
    iteration_count = state.get("iteration_count", 0)
    max_iterations = state.get("max_iterations", 3)
    
    print(f"\nüîß DEBUG route_after_validation:")
    print(f"   Success: {success}")
    print(f"   Iteration: {iteration_count}")
    print(f"   Max iterations: {max_iterations}")
    print(f"   Next node from state: {state.get('next_node', 'N/A')}")
    
    if success:
        print("   ‚Üí Routing to: responder (success)")
        return "responder"
    elif iteration_count >= max_iterations:
        print("   ‚Üí Routing to: responder (max iterations reached)")
        return "responder"
    else:
        print("   ‚Üí Routing to: clasificar (continue iteration)")
        return "clasificar"

# ======================
# 6. Construir el grafo
# ======================
def create_graph():
    graph = StateGraph(AgentState)

    # Nodos
    graph.add_node("clasificar", node_clasificar)
    graph.add_node("ejecutar_python", node_ejecutar_python)
    graph.add_node("validar", node_validar_y_decidir)
    graph.add_node("responder", node_responder)

    # Punto de entrada
    graph.set_entry_point("clasificar")

    # Flujo principal
    graph.add_edge("clasificar", "ejecutar_python")
    graph.add_edge("ejecutar_python", "validar")
    
    # Enrutamiento condicional desde validaci√≥n
    graph.add_conditional_edges("validar", route_after_validation)
    
    # Fin del grafo
    graph.add_edge("responder", END)

    # Compilar con o sin checkpointer seg√∫n est√© disponible
    if checkpoint_saver is not None:
        return graph.compile(checkpointer=checkpoint_saver)
    else:
        print("‚ö†Ô∏è Compilando grafo sin checkpoints")
        return graph.compile()

def main():
    app = create_graph()
    
    print("‚úÖ Base de datos PostgreSQL configurada correctamente")
    print("‚úÖ Sistema de checkpoints activado")
    print("üöÄ Sistema de An√°lisis de Datos con Iteraci√≥n Inteligente")
    print("   Basado en LangGraph con propagaci√≥n de errores")
    print("   Escribe 'salir' para terminar\n")
    
    # Generar un thread_id √∫nico para esta sesi√≥n
    import uuid
    session_id = str(uuid.uuid4())
    print(f"üîó Session ID: {session_id}")
    
    while True:
        query = input("Pregunta sobre el dataset (o 'salir'): ")
        if query.lower() == "salir":
            break

        # Estado inicial con thread_id
        initial_state = {
            "query": query,
            "action": "",
            "result": None,
            "thought": "",
            "history": [],
            "execution_history": [],
            "iteration_count": 0,
            "max_iterations": 3,
            "df_info": {},
            "success": False,
            "final_error": None,
            "next_node": "clasificar",
            "thread_id": session_id  # ID √∫nico para los checkpoints
        }

        # Configuraci√≥n para el checkpointer
        config = {"configurable": {"thread_id": session_id}}

        print(f"\n{'='*60}")
        print(f"üîÑ Procesando consulta: {query}")
        print(f"{'='*60}")
        
        try:
            final_state = app.invoke(initial_state, config=config)
            
            print(f"\nüìä RESUMEN DE EJECUCI√ìN:")
            print(f"   Iteraciones totales: {final_state['iteration_count']}")
            print(f"   √âxito: {final_state.get('success', False)}")
            if not final_state.get('success', False):
                print(f"   Error final: {final_state.get('final_error', 'N/A')}")
            print(f"   Historial: {len(final_state['history'])} eventos")
            print(f"üíæ Checkpoint guardado autom√°ticamente en PostgreSQL")
            
        except Exception as e:
            print(f"‚ùå Error cr√≠tico en el sistema: {e}")
            
        print(f"\n{'-'*60}\n")


def list_saved_checkpoints():
    """Funci√≥n para listar los checkpoints guardados en la BD"""
    try:
        # Conectar a la BD y consultar las tablas de checkpoint
        db_config = load_db_config()
        with psycopg.connect(
            host=db_config['host'],
            port=db_config['port'],
            user=db_config['user'],
            password=db_config['password'],
            dbname=db_config['database']
        ) as conn:
            with conn.cursor() as cursor:
                # Consultar checkpoints
                cursor.execute("SELECT thread_id, checkpoint_id, created_at FROM checkpoints ORDER BY created_at DESC LIMIT 10;")
                results = cursor.fetchall()
                
                print("üìã √öltimos 10 checkpoints guardados:")
                for row in results:
                    print(f"   Thread: {row[0][:8]}... | Checkpoint: {row[1][:8]}... | Fecha: {row[2]}")
        
    except Exception as e:
        print(f"‚ùå Error consultando checkpoints: {e}")


if __name__ == "__main__":
    main()

