import os
import pandas as pd
import psycopg
from typing import Optional
from database import load_db_config, data_connection
from config import ENABLE_AUTO_SAVE_TO_DB
import re
from datetime import datetime, date

# Variables globales para el dataset
dataset_info = None
df = None
dataset_loaded = False

def get_postgres_data_types():
    """
    Mapeo de tipos de pandas a tipos PostgreSQL optimizados.
    """
    return {
        'int64': 'BIGINT',
        'int32': 'INTEGER',
        'int16': 'SMALLINT',
        'int8': 'SMALLINT',
        'float64': 'DOUBLE PRECISION',
        'float32': 'REAL',
        'object': 'TEXT',
        'bool': 'BOOLEAN',
        'datetime64[ns]': 'TIMESTAMP',
        'timedelta64[ns]': 'INTERVAL',
        'category': 'TEXT'
    }

def sanitize_column_name(column_name: str) -> str:
    """
    Limpia nombres de columnas para PostgreSQL.
    Convierte a min√∫sculas, reemplaza espacios y caracteres especiales.
    """
    import re
    # Convertir a min√∫sculas
    clean_name = column_name.lower()
    # Reemplazar espacios y caracteres especiales con guiones bajos
    clean_name = re.sub(r'[^a-z0-9_]', '_', clean_name)
    # Eliminar guiones bajos consecutivos
    clean_name = re.sub(r'_+', '_', clean_name)
    # Eliminar guiones bajos al inicio y final
    clean_name = clean_name.strip('_')
    # Asegurar que no empiece con n√∫mero
    if clean_name and clean_name[0].isdigit():
        clean_name = f'col_{clean_name}'

    return clean_name or 'unnamed_column'

def check_dataset_table_exists(connection=None, table_name=None, table_schema='public'):
    """
    Verifica si una tabla espec√≠fica existe en PostgreSQL.
    Ya no usa valores por defecto de config, requiere table_name expl√≠cito.
    """
    conn = connection

    if conn is None:
        print("‚ö†Ô∏è No se puede verificar tabla: no hay conexi√≥n disponible")
        return False

    if table_name is None:
        print("‚ö†Ô∏è No se especific√≥ nombre de tabla para verificar")
        return False

    try:
        with conn.cursor() as cursor:
            cursor.execute("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables
                    WHERE table_schema = %s
                    AND table_name = %s
                )
            """, (table_schema, table_name))

            exists = cursor.fetchone()[0]
            # print(f"üîç Tabla '{table_name}' {'existe' if exists else 'no existe'} en BD")
            return exists

    except Exception as e:
        print(f"‚ö†Ô∏è Error verificando tabla {table_name}: {e}")
        return False

def get_dataset_table_info_by_name(table_name, connection=None):
    """
    Obtiene informaci√≥n de una tabla espec√≠fica por nombre.
    """
    conn = connection

    if conn is None:
        try:
            db_config = load_db_config()
            temp_connection_string = f"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}"
            conn = psycopg.connect(temp_connection_string)
            temp_connection = True
        except Exception as e:
            return None
    else:
        temp_connection = False

    try:
        with conn.cursor() as cursor:
            # Obtener informaci√≥n de columnas
            cursor.execute("""
                SELECT column_name, data_type, is_nullable
                FROM information_schema.columns
                WHERE table_schema = 'public' AND table_name = %s
                ORDER BY ordinal_position
            """, (table_name,))

            columns_info = cursor.fetchall()

            # Obtener conteo de filas
            cursor.execute(f'SELECT COUNT(*) FROM public."{table_name}"')
            row_count = cursor.fetchone()[0]

            # Formatear informaci√≥n
            columns = [col[0] for col in columns_info]
            dtypes = {col[0]: col[1] for col in columns_info}

            return {
                "columns": columns,
                "dtypes": dtypes,
                "row_count": row_count,
                "table_name": table_name
            }

    except Exception as e:
        print(f"‚ö†Ô∏è Error obteniendo informaci√≥n de tabla {table_name}: {e}")
        return None
    finally:
        if temp_connection:
            conn.close()

def list_stored_tables(connection=None):
    """
    Lista todas las tablas almacenadas en la BD, excluyendo tablas del sistema.
    """
    # Intentar m√∫ltiples fuentes de conexi√≥n
    conn = connection

    if conn is None:
        # Crear conexi√≥n temporal si no hay ninguna disponible
        try:
            db_config = load_db_config()
            temp_connection_string = f"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}"
            conn = psycopg.connect(temp_connection_string)
            temp_connection = True
            # print("üîó Conexi√≥n temporal creada para listar tablas")
        except Exception as e:
            print(f"‚ö†Ô∏è No se pudo crear conexi√≥n para listar tablas: {e}")
            return []
    else:
        temp_connection = False

    try:
        with conn.cursor() as cursor:
            # Primera consulta: verificar todas las tablas en el esquema public
            cursor.execute("""
                SELECT table_name, table_type
                FROM information_schema.tables
                WHERE table_schema = 'public'
                ORDER BY table_name
            """)

            all_tables = cursor.fetchall()

            # Filtrar tablas del sistema y tablas de checkpoint
            excluded_tables = {
                'checkpoint_blobs',
                'checkpoint_migrations',
                'checkpoint_writes',
                'checkpoints',
                'document_registry'
            }

            dataset_tables = []

            for table_name, table_type in all_tables:
                # Solo agregar tablas que no sean del sistema ni de checkpoints
                if table_name not in excluded_tables:
                    dataset_tables.append(table_name)

            return dataset_tables

    except Exception as e:
        print(f"‚ö†Ô∏è Error listando tablas: {e}")
        return []
    finally:
        # Cerrar conexi√≥n temporal si se cre√≥
        if temp_connection:
            conn.close()

def create_dataset_table_from_df(df: pd.DataFrame, connection=None, table_name=None, table_schema='public', semantic_description=None):
    """
    Crea una tabla en PostgreSQL desde un DataFrame.
    Requiere table_name expl√≠cito, no usa valores por defecto de config.
    """
    conn = connection

    if conn is None:
        print("‚ö†Ô∏è No se puede crear tabla: no hay conexi√≥n disponible")
        return False, {}

    if table_name is None:
        print("‚ö†Ô∏è No se especific√≥ nombre de tabla")
        return False, {}

    try:
        postgres_types = get_postgres_data_types()

        # Limpiar nombres de columnas y crear mapeo
        original_columns = list(df.columns)
        clean_columns = [sanitize_column_name(col) for col in original_columns]
        column_mapping = dict(zip(original_columns, clean_columns))

        print(f"üìù Creando tabla '{table_name}' con {len(df.columns)} columnas...")

        with conn.cursor() as cursor:
            # Construir DDL para crear tabla
            column_definitions = []

            for original_col, clean_col in column_mapping.items():
                # Obtener tipo de pandas
                pandas_type = str(df[original_col].dtype)

                # Mapear a tipo PostgreSQL
                postgres_type = postgres_types.get(pandas_type, 'TEXT')

                # Manejar casos especiales
                if pandas_type == 'object':
                    # Para object, verificar si es fecha o texto
                    try:
                        pd.to_datetime(df[original_col], errors='raise')
                        postgres_type = 'TIMESTAMP'
                    except:
                        # Estimar longitud m√°xima para TEXT
                        max_length = df[original_col].astype(str).str.len().max()
                        if max_length and max_length < 255:
                            postgres_type = f'VARCHAR({max_length + 50})'
                        else:
                            postgres_type = 'TEXT'

                column_definitions.append(f'"{clean_col}" {postgres_type}')
                print(f"   {original_col} -> {clean_col} ({pandas_type} -> {postgres_type})")

            # Crear tabla CON columna de descripci√≥n sem√°ntica
            create_table_sql = f"""
                CREATE TABLE {table_schema}.{table_name} (
                    id SERIAL PRIMARY KEY,
                    {', '.join(column_definitions)},
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    semantic_description TEXT
                )
            """

            cursor.execute(create_table_sql)

            # Si se proporcion√≥ descripci√≥n, agregarla como comentario de tabla
            if semantic_description:
                # Escapar comillas simples en la descripci√≥n
                escaped_description = semantic_description.replace("'", "''")
                comment_sql = f"""
                    COMMENT ON TABLE {table_schema}.{table_name} IS '{escaped_description}'
                """
                cursor.execute(comment_sql)

            conn.commit()

            print(f"‚úÖ Tabla '{table_name}' creada exitosamente")
            if semantic_description:
                print(f"üß† Descripci√≥n sem√°ntica almacenada")

            return True, column_mapping

    except Exception as e:
        print(f"‚ùå Error creando tabla {table_name}: {e}")
        if conn:
            conn.rollback()
        return False, {}

def insert_dataframe_to_table(df: pd.DataFrame, column_mapping: dict, connection=None, table_name=None, table_schema='public', semantic_description=None):
    """
    Inserta los datos del DataFrame en la tabla PostgreSQL.
    MODIFICADO: Requiere table_name expl√≠cito, no usa valores por defecto de config.
    """
    conn = connection

    if conn is None:
        print("‚ö†Ô∏è No se puede insertar datos: no hay conexi√≥n disponible")
        return False

    if table_name is None:
        print("‚ö†Ô∏è No se especific√≥ nombre de tabla")
        return False

    try:
        # Renombrar columnas seg√∫n el mapeo
        df_clean = df.rename(columns=column_mapping)

        print(f"üì• Insertando {len(df_clean)} filas en la tabla '{table_name}'...")

        # Preparar datos para inserci√≥n (con descripci√≥n sem√°ntica)
        columns_list = list(column_mapping.values())
        if semantic_description:
            columns_list.append('semantic_description')
            placeholders = ', '.join(['%s'] * (len(columns_list)))
        else:
            placeholders = ', '.join(['%s'] * len(columns_list))

        columns_str = ', '.join([f'"{col}"' for col in columns_list])

        insert_sql = f"""
            INSERT INTO {table_schema}.{table_name}
            ({columns_str}) VALUES ({placeholders})
        """

        # Convertir DataFrame a lista de tuplas
        data_rows = []
        for _, row in df_clean.iterrows():
            row_data = []
            for col in column_mapping.values():
                value = row[col]
                if pd.isna(value):
                    row_data.append(None)
                elif isinstance(value, (pd.Timestamp, pd.Timedelta)):
                    row_data.append(value.to_pydatetime() if hasattr(value, 'to_pydatetime') else str(value))
                else:
                    row_data.append(value)

            # Agregar descripci√≥n sem√°ntica al final de cada fila
            if semantic_description:
                row_data.append(semantic_description)

            data_rows.append(tuple(row_data))

        # Inserci√≥n por lotes
        with conn.cursor() as cursor:
            cursor.executemany(insert_sql, data_rows)
            conn.commit()

            # Verificar inserci√≥n
            cursor.execute(f"SELECT COUNT(*) FROM {table_schema}.{table_name}")
            inserted_count = cursor.fetchone()[0]

            print(f"‚úÖ {inserted_count} filas insertadas correctamente en '{table_name}'")
            return True

    except Exception as e:
        print(f"‚ùå Error insertando datos en {table_name}: {e}")
        if conn:
            conn.rollback()
        return False

def generate_semantic_description_with_llm(df: pd.DataFrame, table_name: str, filename: str = None) -> str:
    """
    Genera una descripci√≥n sem√°ntica del dataset usando LLM.
    Ya no requiere ruta de archivo, usa filename opcional.
    """
    from nodes import llm_documentHandler

    try:
        # Obtener muestra de datos (primeras 5 filas)
        sample_data = df.head(5).to_string()

        # Informaci√≥n estructural
        columns_info = ", ".join(df.columns.tolist())
        dtypes_info = df.dtypes.to_string()
        row_count = len(df)

        # Estad√≠sticas b√°sicas para columnas num√©ricas
        numeric_stats = ""
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            numeric_stats = df[numeric_cols].describe().to_string()

        filename_str = f"- Nombre de archivo: {filename}" if filename else ""

        prompt = f"""
            Analiza este dataset y genera una descripci√≥n sem√°ntica clara y concisa.

            INFORMACI√ìN DEL DATASET:
            {filename_str}
            - Nombre de tabla: {table_name}
            - Cantidad de filas: {row_count}
            - Columnas ({len(df.columns)}): {columns_info}

            TIPOS DE DATOS:
            {dtypes_info}

            MUESTRA DE DATOS (primeras 5 filas):
            {sample_data}

            {f"ESTAD√çSTICAS NUM√âRICAS:{numeric_stats}" if numeric_stats else ""}

            TAREA:
            Genera una descripci√≥n sem√°ntica de 2-3 oraciones que explique:
            1. Qu√© tipo de datos contiene este dataset
            2. Para qu√© an√°lisis o consultas podr√≠a ser √∫til
            3. Caracter√≠sticas principales (temporal, geogr√°fico, transaccional, etc.)

            La descripci√≥n debe ser clara, directa y √∫til para que un LLM pueda decidir si este dataset es relevante para una consulta de usuario.

            Responde SOLO con la descripci√≥n, sin formato adicional.
        """

        response = llm_documentHandler.invoke(prompt).content.strip()

        print(f"üìù Descripci√≥n generada para '{table_name}':")
        print(f"   {response[:150]}...")

        return response

    except Exception as e:
        print(f"‚ö†Ô∏è Error generando descripci√≥n sem√°ntica: {e}")
        # Fallback a descripci√≥n b√°sica
        return f"Dataset con {len(df.columns)} columnas y {len(df)} filas. Columnas principales: {', '.join(df.columns.tolist()[:5])}"

def ensure_dataset_loaded(state=None):
    """
    Funci√≥n para cargar el dataset solo cuando sea necesario.
    Ahora mapea autom√°ticamente nombres parciales al nombre completo de la tabla.
    """
    global dataset_info, df, dataset_loaded

    # Determinar qu√© dataset cargar
    if state and state.get("selected_dataset"):
        target_dataset = state["selected_dataset"]
        print(f"üéØ Cargando dataset seleccionado: {target_dataset}")
    else:
        print("‚ùå No se especific√≥ dataset y no hay fallback por defecto")
        return False

    # Verificar si ya est√° cargado el dataset correcto
    if dataset_loaded and df is not None and dataset_info:
        current_dataset = dataset_info.get("table_name", "")
        if current_dataset == target_dataset:
            print("‚úÖ Dataset correcto ya est√° cargado en memoria")
            return True
        else:
            print(f"üîÑ Dataset actual ({current_dataset}) no coincide, recargando...")
            dataset_loaded = False

    print(f"üîÑ Cargando dataset: {target_dataset}")

    # Crear conexi√≥n temporal
    dataset_connection = None
    try:
        db_config = load_db_config()
        connection_string = f"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}"
        dataset_connection = psycopg.connect(connection_string)
        print("üîó Conexi√≥n temporal creada para dataset")
    except Exception as e:
        print(f"‚ö†Ô∏è Error creando conexi√≥n: {e}")
        return False

    try:
        # Buscar la tabla real (puede ser nombre parcial)
        actual_table_name = target_dataset

        with dataset_connection.cursor() as cursor:
            # Verificar si existe exactamente como se pas√≥
            cursor.execute("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables
                    WHERE table_schema = 'public'
                    AND table_name = %s
                )
            """, (target_dataset,))
            table_exists = cursor.fetchone()[0]

            if not table_exists:
                # Buscar tabla que empiece con el nombre dado
                print(f"üîç Buscando tabla que coincida con '{target_dataset}'...")

                cursor.execute("""
                    SELECT table_name
                    FROM information_schema.tables
                    WHERE table_schema = 'public'
                    AND table_name LIKE %s
                    AND table_name NOT IN ('document_registry', 'checkpoints', 'checkpoint_writes')
                    LIMIT 1
                """, (target_dataset + '%',))

                result = cursor.fetchone()
                if result:
                    actual_table_name = result[0]
                    print(f"üîÑ Mapeado: '{target_dataset}' ‚Üí '{actual_table_name}'")
                    # IMPORTANTE: Actualizar el estado con el nombre real
                    if state:
                        state["selected_dataset"] = actual_table_name
                else:
                    print(f"‚ùå Tabla '{target_dataset}' no existe en la BD")
                    return False

        # Cargar desde la BD usando el nombre real
        print(f"üîÑ Cargando '{actual_table_name}' desde PostgreSQL...")

        with dataset_connection.cursor() as cursor:
            # Cargar todos los datos de la tabla
            cursor.execute(f'SELECT * FROM public."{actual_table_name}"')
            rows = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description]
            df = pd.DataFrame(rows, columns=columns)

            # Eliminar columnas del sistema si existen
            system_columns = ['created_at', 'semantic_description']
            for col in system_columns:
                if col in df.columns:
                    df = df.drop(columns=[col])

            dataset_info = {
                "columns": list(df.columns),
                "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
                "row_count": len(df),
                "table_name": actual_table_name  # Usar el nombre real
            }
            dataset_loaded = True
            print(f"‚úÖ Dataset '{actual_table_name}' cargado desde BD: {df.shape}")
            return True

    except Exception as e:
        print(f"‚ùå Error cargando dataset desde BD: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        if dataset_connection:
            dataset_connection.close()

def clean_mixed_date_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    Detecta columnas con mezcla de datetime/fechas y n√∫meros decimales.
    Solo en esos casos, convierte las fechas/datetime a formato decimal (mes.d√≠a).
    
    Ejemplos de conversi√≥n:
    - datetime(2025, 9, 1) -> 1.9
    - "2025-09-01" -> 1.9
    - "2025-09-04" -> 4.9
    - 3.14 -> 3.14 (sin cambios)
    
    Args:
        df: DataFrame a procesar
        
    Returns:
        DataFrame con columnas procesadas
    """
    df_copy = df.copy()
    
    for col in df_copy.columns:
        # An√°lisis de la columna
        tiene_datetime = False
        tiene_numeros_puros = False
        
        # Analizar valores no nulos
        valores_no_nulos = df_copy[col].dropna()
        
        if len(valores_no_nulos) == 0:
            continue
        
        # Contar tipos de datos
        count_datetime = 0
        count_numeros = 0
        
        for valor in valores_no_nulos:
            # Detectar datetime objects
            if isinstance(valor, (datetime, date, pd.Timestamp)):
                count_datetime += 1
            # Detectar n√∫meros (int, float) pero NO strings que parezcan fechas
            elif isinstance(valor, (int, float)) and not isinstance(valor, bool):
                # Verificar que sea un n√∫mero real, no NaN
                if pd.notna(valor):
                    count_numeros += 1
            # Detectar strings con formato de fecha
            elif isinstance(valor, str):
                valor_str = valor.strip()
                # Patrones de fecha
                patrones_fecha = [
                    r'^\d{4}-\d{1,2}-\d{1,2}',      # YYYY-MM-DD
                    r'^\d{1,2}/\d{1,2}/\d{4}',      # MM/DD/YYYY
                    r'^\d{1,2}-\d{1,2}-\d{4}',      # MM-DD-YYYY
                ]
                es_fecha = any(re.match(patron, valor_str) for patron in patrones_fecha)
                
                if es_fecha:
                    count_datetime += 1
                else:
                    # Intentar convertir a n√∫mero
                    try:
                        float(valor_str)
                        count_numeros += 1
                    except:
                        pass
        
        tiene_datetime = count_datetime > 0
        tiene_numeros_puros = count_numeros > 0
        
        # SOLO procesar si tiene AMBOS: datetime/fechas Y n√∫meros puros
        if tiene_datetime and tiene_numeros_puros:
            print(f"üîÑ Columna '{col}' tiene mezcla ({count_datetime} fechas, {count_numeros} n√∫meros) - Convirtiendo fechas a decimal...")
            df_copy[col] = df_copy[col].apply(_convertir_fecha_a_decimal)
        elif tiene_datetime and not tiene_numeros_puros:
            print(f"‚ÑπÔ∏è Columna '{col}' solo tiene fechas ({count_datetime}) - Sin cambios")
        elif tiene_numeros_puros and not tiene_datetime:
            print(f"‚ÑπÔ∏è Columna '{col}' solo tiene n√∫meros ({count_numeros}) - Sin cambios")
    
    return df_copy


def _convertir_fecha_a_decimal(valor):
    """
    Convierte fechas/datetime a formato decimal d√≠a.mes
    Mantiene n√∫meros decimales como est√°n.
    
    Ejemplos:
    - datetime(2025, 9, 1) -> 1.9
    - "2025-09-01" -> 1.9
    - "2025-09-04" -> 4.9
    - 3.14 -> 3.14 (sin cambios)
    """
    if pd.isna(valor):
        return valor
    
    # Caso 1: datetime, date o Timestamp objects
    if isinstance(valor, (datetime, date, pd.Timestamp)):
        day = valor.day
        month = valor.month
        return float(f"{day}.{month}")
    
    # Caso 2: N√∫meros puros (int, float)
    if isinstance(valor, (int, float)) and not isinstance(valor, bool):
        return float(valor)
    
    # Caso 3: Strings
    if isinstance(valor, str):
        valor_str = valor.strip()
        
        # Patr√≥n 1: YYYY-MM-DD o YYYY-M-D
        match = re.match(r'^(\d{4})-(\d{1,2})-(\d{1,2})', valor_str)
        if match:
            year, month, day = match.groups()
            return float(f"{int(day)}.{int(month)}")
        
        # Patr√≥n 2: MM/DD/YYYY o M/D/YYYY
        match = re.match(r'^(\d{1,2})/(\d{1,2})/(\d{4})', valor_str)
        if match:
            month, day, year = match.groups()
            return float(f"{int(day)}.{int(month)}")
        
        # Patr√≥n 3: MM-DD-YYYY o M-D-YYYY
        match = re.match(r'^(\d{1,2})-(\d{1,2})-(\d{4})', valor_str)
        if match:
            month, day, year = match.groups()
            return float(f"{int(day)}.{int(month)}")
        
        # Si no es fecha, intentar convertir a n√∫mero
        try:
            return float(valor_str)
        except:
            return valor
    
    # Valor sin cambios si no coincide con ning√∫n caso
    return valor
